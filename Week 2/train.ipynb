{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SummerCourse Week2 HW\n## [GitHub](https://github.com/FCWTW/SummerCourse/tree/main/Week%202)\n## Import library","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport optuna\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-09T11:24:24.470105Z","iopub.execute_input":"2024-08-09T11:24:24.470766Z","iopub.status.idle":"2024-08-09T11:24:30.392216Z","shell.execute_reply.started":"2024-08-09T11:24:24.470740Z","shell.execute_reply":"2024-08-09T11:24:30.391276Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define a custom dataset class","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, csv_file, transform=None):\n        self.data_frame = pd.read_csv(csv_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        image = Image.fromarray(self.data_frame.iloc[idx, 1:].values.reshape(28, 28).astype(np.uint8))\n        label = int(self.data_frame.iloc[idx, 0])\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:30.393926Z","iopub.execute_input":"2024-08-09T11:24:30.394363Z","iopub.status.idle":"2024-08-09T11:24:30.400982Z","shell.execute_reply.started":"2024-08-09T11:24:30.394335Z","shell.execute_reply":"2024-08-09T11:24:30.400028Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(degrees=45),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:30.402156Z","iopub.execute_input":"2024-08-09T11:24:30.402452Z","iopub.status.idle":"2024-08-09T11:24:30.413200Z","shell.execute_reply.started":"2024-08-09T11:24:30.402430Z","shell.execute_reply":"2024-08-09T11:24:30.412400Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Define dataset and dataloader","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/fashionmnist/fashion-mnist_train.csv'\ntest_path = '/kaggle/input/fashionmnist/fashion-mnist_test.csv'\n\ntrain_data = MyDataset(csv_file=train_path, transform=train_transform)\ntest_data = MyDataset(csv_file=test_path, transform=test_transform)\ntestLen = int(len(test_data) * 0.5)\nvalLen = len(test_data) - testLen\ntest_data, val_data = random_split(test_data, [testLen, valLen])","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:30.415163Z","iopub.execute_input":"2024-08-09T11:24:30.415440Z","iopub.status.idle":"2024-08-09T11:24:37.061710Z","shell.execute_reply.started":"2024-08-09T11:24:30.415418Z","shell.execute_reply":"2024-08-09T11:24:37.060625Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Define CNN model","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, dropout_rate):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n        self.fc2 = nn.Linear(128, 10)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=dropout_rate)\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 7 * 7)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:37.062890Z","iopub.execute_input":"2024-08-09T11:24:37.063150Z","iopub.status.idle":"2024-08-09T11:24:37.071829Z","shell.execute_reply.started":"2024-08-09T11:24:37.063129Z","shell.execute_reply":"2024-08-09T11:24:37.070788Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Train function","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, trial):\n    best_accuracy = 0.0\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_train += labels.size(0)\n            correct_train += (predicted == labels).sum().item()\n\n        train_loss = running_loss / len(train_loader.dataset)\n        train_accuracy = correct_train / total_train\n        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n\n        # Evaluate on validation set every epoch\n        model.eval()\n        running_val_loss = 0.0\n        correct_val = 0\n        total_val = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                running_val_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n\n            val_loss = running_val_loss / len(val_loader.dataset)\n            val_accuracy = correct_val / total_val\n\n            # Save model weights if validation accuracy is improved\n            if val_accuracy > best_accuracy:\n                torch.save(model.state_dict(), f'best_model_{trial.number}.pth')\n                best_accuracy = val_accuracy\n\n            print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n\n    # Return the best accuracy for Optuna to maximize\n    return best_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:37.073156Z","iopub.execute_input":"2024-08-09T11:24:37.073571Z","iopub.status.idle":"2024-08-09T11:24:37.087938Z","shell.execute_reply.started":"2024-08-09T11:24:37.073541Z","shell.execute_reply":"2024-08-09T11:24:37.087028Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Test function","metadata":{}},{"cell_type":"code","source":"def test_model(model, test_loader, criterion):\n    model.eval()\n    running_test_loss = 0.0\n    correct_test = 0\n    total_test = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_test_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n    test_loss = running_test_loss / len(test_loader.dataset)\n    test_accuracy = correct_test / total_test\n\n    print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:37.088961Z","iopub.execute_input":"2024-08-09T11:24:37.089247Z","iopub.status.idle":"2024-08-09T11:24:37.102862Z","shell.execute_reply.started":"2024-08-09T11:24:37.089216Z","shell.execute_reply":"2024-08-09T11:24:37.102093Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Search better hyperparameters with Optuna","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    # Define hyperparameters\n    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n    batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n\n    # Initialize model, loss and optimizer\n    model = Net(dropout_rate=dropout_rate).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n\n    # Create DataLoader with current batch size\n    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n    \n    # Train the model\n    best_accuracy = train_model(model, train_loader, val_loader, criterion, optimizer, 20, trial)\n\n    # Return the best accuracy as the objective to maximize\n    return best_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:37.103872Z","iopub.execute_input":"2024-08-09T11:24:37.104124Z","iopub.status.idle":"2024-08-09T11:24:37.113772Z","shell.execute_reply.started":"2024-08-09T11:24:37.104102Z","shell.execute_reply":"2024-08-09T11:24:37.112996Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## train model","metadata":{}},{"cell_type":"code","source":"# Run Optuna optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=5)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T11:24:37.114778Z","iopub.execute_input":"2024-08-09T11:24:37.115089Z","iopub.status.idle":"2024-08-09T12:27:40.882979Z","shell.execute_reply.started":"2024-08-09T11:24:37.115061Z","shell.execute_reply":"2024-08-09T12:27:40.882097Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"[I 2024-08-09 11:24:37,123] A new study created in memory with name: no-name-b6711a2b-db2c-4964-ad2d-a391f8cd27e7\n/tmp/ipykernel_34/3042987186.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n/tmp/ipykernel_34/3042987186.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Training Loss: 0.7954, Training Accuracy: 0.7050\nValidation Loss: 0.5935, Validation Accuracy: 0.7846\nEpoch 2/20, Training Loss: 0.5776, Training Accuracy: 0.7863\nValidation Loss: 0.5013, Validation Accuracy: 0.8158\nEpoch 3/20, Training Loss: 0.5153, Training Accuracy: 0.8119\nValidation Loss: 0.4492, Validation Accuracy: 0.8384\nEpoch 4/20, Training Loss: 0.4867, Training Accuracy: 0.8232\nValidation Loss: 0.4373, Validation Accuracy: 0.8400\nEpoch 5/20, Training Loss: 0.4680, Training Accuracy: 0.8296\nValidation Loss: 0.4089, Validation Accuracy: 0.8488\nEpoch 6/20, Training Loss: 0.4449, Training Accuracy: 0.8384\nValidation Loss: 0.4447, Validation Accuracy: 0.8422\nEpoch 7/20, Training Loss: 0.4376, Training Accuracy: 0.8399\nValidation Loss: 0.3726, Validation Accuracy: 0.8652\nEpoch 8/20, Training Loss: 0.4284, Training Accuracy: 0.8449\nValidation Loss: 0.3637, Validation Accuracy: 0.8724\nEpoch 9/20, Training Loss: 0.4210, Training Accuracy: 0.8482\nValidation Loss: 0.4030, Validation Accuracy: 0.8526\nEpoch 10/20, Training Loss: 0.4127, Training Accuracy: 0.8501\nValidation Loss: 0.3578, Validation Accuracy: 0.8734\nEpoch 11/20, Training Loss: 0.4088, Training Accuracy: 0.8517\nValidation Loss: 0.3487, Validation Accuracy: 0.8718\nEpoch 12/20, Training Loss: 0.4063, Training Accuracy: 0.8540\nValidation Loss: 0.3260, Validation Accuracy: 0.8832\nEpoch 13/20, Training Loss: 0.3974, Training Accuracy: 0.8557\nValidation Loss: 0.3476, Validation Accuracy: 0.8762\nEpoch 14/20, Training Loss: 0.3908, Training Accuracy: 0.8582\nValidation Loss: 0.3491, Validation Accuracy: 0.8762\nEpoch 15/20, Training Loss: 0.3898, Training Accuracy: 0.8579\nValidation Loss: 0.3313, Validation Accuracy: 0.8770\nEpoch 16/20, Training Loss: 0.3826, Training Accuracy: 0.8623\nValidation Loss: 0.3136, Validation Accuracy: 0.8874\nEpoch 17/20, Training Loss: 0.3812, Training Accuracy: 0.8616\nValidation Loss: 0.3265, Validation Accuracy: 0.8800\nEpoch 18/20, Training Loss: 0.3804, Training Accuracy: 0.8619\nValidation Loss: 0.3222, Validation Accuracy: 0.8872\nEpoch 19/20, Training Loss: 0.3772, Training Accuracy: 0.8624\nValidation Loss: 0.3245, Validation Accuracy: 0.8806\nEpoch 20/20, Training Loss: 0.3750, Training Accuracy: 0.8642\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-09 11:37:10,156] Trial 0 finished with value: 0.888 and parameters: {'learning_rate': 0.00328964155258187, 'batch_size': 128, 'dropout_rate': 0.1381197686826482}. Best is trial 0 with value: 0.888.\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.3230, Validation Accuracy: 0.8880\nEpoch 1/20, Training Loss: 1.5725, Training Accuracy: 0.4430\nValidation Loss: 1.0107, Validation Accuracy: 0.6622\nEpoch 2/20, Training Loss: 1.0785, Training Accuracy: 0.6103\nValidation Loss: 0.8214, Validation Accuracy: 0.7032\nEpoch 3/20, Training Loss: 0.9493, Training Accuracy: 0.6547\nValidation Loss: 0.7630, Validation Accuracy: 0.7224\nEpoch 4/20, Training Loss: 0.8809, Training Accuracy: 0.6774\nValidation Loss: 0.7185, Validation Accuracy: 0.7284\nEpoch 5/20, Training Loss: 0.8339, Training Accuracy: 0.6931\nValidation Loss: 0.6912, Validation Accuracy: 0.7414\nEpoch 6/20, Training Loss: 0.8038, Training Accuracy: 0.7054\nValidation Loss: 0.6651, Validation Accuracy: 0.7468\nEpoch 7/20, Training Loss: 0.7834, Training Accuracy: 0.7121\nValidation Loss: 0.6413, Validation Accuracy: 0.7564\nEpoch 8/20, Training Loss: 0.7576, Training Accuracy: 0.7206\nValidation Loss: 0.6386, Validation Accuracy: 0.7564\nEpoch 9/20, Training Loss: 0.7451, Training Accuracy: 0.7250\nValidation Loss: 0.6208, Validation Accuracy: 0.7654\nEpoch 10/20, Training Loss: 0.7320, Training Accuracy: 0.7278\nValidation Loss: 0.6130, Validation Accuracy: 0.7660\nEpoch 11/20, Training Loss: 0.7183, Training Accuracy: 0.7344\nValidation Loss: 0.6045, Validation Accuracy: 0.7690\nEpoch 12/20, Training Loss: 0.7066, Training Accuracy: 0.7398\nValidation Loss: 0.5956, Validation Accuracy: 0.7736\nEpoch 13/20, Training Loss: 0.6965, Training Accuracy: 0.7430\nValidation Loss: 0.5985, Validation Accuracy: 0.7732\nEpoch 14/20, Training Loss: 0.6863, Training Accuracy: 0.7462\nValidation Loss: 0.5803, Validation Accuracy: 0.7848\nEpoch 15/20, Training Loss: 0.6799, Training Accuracy: 0.7490\nValidation Loss: 0.5747, Validation Accuracy: 0.7856\nEpoch 16/20, Training Loss: 0.6702, Training Accuracy: 0.7536\nValidation Loss: 0.5740, Validation Accuracy: 0.7838\nEpoch 17/20, Training Loss: 0.6582, Training Accuracy: 0.7568\nValidation Loss: 0.5552, Validation Accuracy: 0.7914\nEpoch 18/20, Training Loss: 0.6559, Training Accuracy: 0.7597\nValidation Loss: 0.5530, Validation Accuracy: 0.7972\nEpoch 19/20, Training Loss: 0.6437, Training Accuracy: 0.7639\nValidation Loss: 0.5405, Validation Accuracy: 0.7968\nEpoch 20/20, Training Loss: 0.6386, Training Accuracy: 0.7641\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-09 11:49:26,584] Trial 1 finished with value: 0.804 and parameters: {'learning_rate': 0.00011051591577190123, 'batch_size': 256, 'dropout_rate': 0.4280118236657635}. Best is trial 0 with value: 0.888.\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.5344, Validation Accuracy: 0.8040\nEpoch 1/20, Training Loss: 1.2331, Training Accuracy: 0.5697\nValidation Loss: 0.8156, Validation Accuracy: 0.7022\nEpoch 2/20, Training Loss: 0.8481, Training Accuracy: 0.6923\nValidation Loss: 0.7058, Validation Accuracy: 0.7338\nEpoch 3/20, Training Loss: 0.7621, Training Accuracy: 0.7181\nValidation Loss: 0.6674, Validation Accuracy: 0.7526\nEpoch 4/20, Training Loss: 0.7168, Training Accuracy: 0.7326\nValidation Loss: 0.6431, Validation Accuracy: 0.7580\nEpoch 5/20, Training Loss: 0.6796, Training Accuracy: 0.7473\nValidation Loss: 0.6137, Validation Accuracy: 0.7698\nEpoch 6/20, Training Loss: 0.6534, Training Accuracy: 0.7590\nValidation Loss: 0.5862, Validation Accuracy: 0.7808\nEpoch 7/20, Training Loss: 0.6341, Training Accuracy: 0.7647\nValidation Loss: 0.5719, Validation Accuracy: 0.7906\nEpoch 8/20, Training Loss: 0.6102, Training Accuracy: 0.7731\nValidation Loss: 0.5598, Validation Accuracy: 0.7952\nEpoch 9/20, Training Loss: 0.5944, Training Accuracy: 0.7823\nValidation Loss: 0.5360, Validation Accuracy: 0.7980\nEpoch 10/20, Training Loss: 0.5758, Training Accuracy: 0.7898\nValidation Loss: 0.5115, Validation Accuracy: 0.8152\nEpoch 11/20, Training Loss: 0.5595, Training Accuracy: 0.7948\nValidation Loss: 0.4950, Validation Accuracy: 0.8244\nEpoch 12/20, Training Loss: 0.5467, Training Accuracy: 0.8007\nValidation Loss: 0.4889, Validation Accuracy: 0.8264\nEpoch 13/20, Training Loss: 0.5341, Training Accuracy: 0.8064\nValidation Loss: 0.4821, Validation Accuracy: 0.8248\nEpoch 14/20, Training Loss: 0.5261, Training Accuracy: 0.8088\nValidation Loss: 0.4613, Validation Accuracy: 0.8380\nEpoch 15/20, Training Loss: 0.5135, Training Accuracy: 0.8144\nValidation Loss: 0.4625, Validation Accuracy: 0.8318\nEpoch 16/20, Training Loss: 0.5065, Training Accuracy: 0.8157\nValidation Loss: 0.4431, Validation Accuracy: 0.8418\nEpoch 17/20, Training Loss: 0.4966, Training Accuracy: 0.8208\nValidation Loss: 0.4570, Validation Accuracy: 0.8374\nEpoch 18/20, Training Loss: 0.4880, Training Accuracy: 0.8222\nValidation Loss: 0.4325, Validation Accuracy: 0.8420\nEpoch 19/20, Training Loss: 0.4803, Training Accuracy: 0.8252\nValidation Loss: 0.4263, Validation Accuracy: 0.8532\nEpoch 20/20, Training Loss: 0.4757, Training Accuracy: 0.8277\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-09 12:01:59,332] Trial 2 finished with value: 0.8532 and parameters: {'learning_rate': 0.0001278986203853944, 'batch_size': 128, 'dropout_rate': 0.1316251467927937}. Best is trial 0 with value: 0.888.\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.4247, Validation Accuracy: 0.8510\nEpoch 1/20, Training Loss: 1.0687, Training Accuracy: 0.6140\nValidation Loss: 0.7118, Validation Accuracy: 0.7302\nEpoch 2/20, Training Loss: 0.7544, Training Accuracy: 0.7201\nValidation Loss: 0.6213, Validation Accuracy: 0.7622\nEpoch 3/20, Training Loss: 0.6838, Training Accuracy: 0.7447\nValidation Loss: 0.5691, Validation Accuracy: 0.7816\nEpoch 4/20, Training Loss: 0.6406, Training Accuracy: 0.7600\nValidation Loss: 0.5452, Validation Accuracy: 0.7992\nEpoch 5/20, Training Loss: 0.6041, Training Accuracy: 0.7752\nValidation Loss: 0.5248, Validation Accuracy: 0.8004\nEpoch 6/20, Training Loss: 0.5814, Training Accuracy: 0.7862\nValidation Loss: 0.4882, Validation Accuracy: 0.8180\nEpoch 7/20, Training Loss: 0.5547, Training Accuracy: 0.7951\nValidation Loss: 0.4710, Validation Accuracy: 0.8256\nEpoch 8/20, Training Loss: 0.5372, Training Accuracy: 0.8030\nValidation Loss: 0.4549, Validation Accuracy: 0.8318\nEpoch 9/20, Training Loss: 0.5202, Training Accuracy: 0.8098\nValidation Loss: 0.4372, Validation Accuracy: 0.8410\nEpoch 10/20, Training Loss: 0.5070, Training Accuracy: 0.8153\nValidation Loss: 0.4248, Validation Accuracy: 0.8474\nEpoch 11/20, Training Loss: 0.4951, Training Accuracy: 0.8216\nValidation Loss: 0.4151, Validation Accuracy: 0.8522\nEpoch 12/20, Training Loss: 0.4856, Training Accuracy: 0.8257\nValidation Loss: 0.4089, Validation Accuracy: 0.8512\nEpoch 13/20, Training Loss: 0.4795, Training Accuracy: 0.8274\nValidation Loss: 0.3992, Validation Accuracy: 0.8574\nEpoch 14/20, Training Loss: 0.4648, Training Accuracy: 0.8313\nValidation Loss: 0.3861, Validation Accuracy: 0.8598\nEpoch 15/20, Training Loss: 0.4596, Training Accuracy: 0.8339\nValidation Loss: 0.3797, Validation Accuracy: 0.8668\nEpoch 16/20, Training Loss: 0.4528, Training Accuracy: 0.8359\nValidation Loss: 0.3766, Validation Accuracy: 0.8634\nEpoch 17/20, Training Loss: 0.4461, Training Accuracy: 0.8390\nValidation Loss: 0.3710, Validation Accuracy: 0.8706\nEpoch 18/20, Training Loss: 0.4403, Training Accuracy: 0.8404\nValidation Loss: 0.3609, Validation Accuracy: 0.8684\nEpoch 19/20, Training Loss: 0.4342, Training Accuracy: 0.8430\nValidation Loss: 0.3582, Validation Accuracy: 0.8706\nEpoch 20/20, Training Loss: 0.4292, Training Accuracy: 0.8445\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-09 12:14:43,278] Trial 3 finished with value: 0.8706 and parameters: {'learning_rate': 0.0004118906802455594, 'batch_size': 128, 'dropout_rate': 0.24657626650224068}. Best is trial 0 with value: 0.888.\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.3613, Validation Accuracy: 0.8696\nEpoch 1/20, Training Loss: 0.9874, Training Accuracy: 0.6299\nValidation Loss: 0.7084, Validation Accuracy: 0.7296\nEpoch 2/20, Training Loss: 0.8226, Training Accuracy: 0.6932\nValidation Loss: 0.6659, Validation Accuracy: 0.7442\nEpoch 3/20, Training Loss: 0.7868, Training Accuracy: 0.7039\nValidation Loss: 0.6943, Validation Accuracy: 0.7028\nEpoch 4/20, Training Loss: 0.7583, Training Accuracy: 0.7146\nValidation Loss: 0.5972, Validation Accuracy: 0.7758\nEpoch 5/20, Training Loss: 0.7536, Training Accuracy: 0.7167\nValidation Loss: 0.6142, Validation Accuracy: 0.7572\nEpoch 6/20, Training Loss: 0.7396, Training Accuracy: 0.7231\nValidation Loss: 0.6004, Validation Accuracy: 0.7804\nEpoch 7/20, Training Loss: 0.7378, Training Accuracy: 0.7259\nValidation Loss: 0.5969, Validation Accuracy: 0.7706\nEpoch 8/20, Training Loss: 0.7326, Training Accuracy: 0.7288\nValidation Loss: 0.6211, Validation Accuracy: 0.7700\nEpoch 9/20, Training Loss: 0.7279, Training Accuracy: 0.7290\nValidation Loss: 0.6257, Validation Accuracy: 0.7652\nEpoch 10/20, Training Loss: 0.7226, Training Accuracy: 0.7309\nValidation Loss: 0.5734, Validation Accuracy: 0.7916\nEpoch 11/20, Training Loss: 0.7253, Training Accuracy: 0.7299\nValidation Loss: 0.5617, Validation Accuracy: 0.7978\nEpoch 12/20, Training Loss: 0.7211, Training Accuracy: 0.7310\nValidation Loss: 0.5791, Validation Accuracy: 0.7838\nEpoch 13/20, Training Loss: 0.7097, Training Accuracy: 0.7365\nValidation Loss: 0.5550, Validation Accuracy: 0.8008\nEpoch 14/20, Training Loss: 0.7130, Training Accuracy: 0.7365\nValidation Loss: 0.5588, Validation Accuracy: 0.7840\nEpoch 15/20, Training Loss: 0.7138, Training Accuracy: 0.7372\nValidation Loss: 0.5487, Validation Accuracy: 0.7968\nEpoch 16/20, Training Loss: 0.7023, Training Accuracy: 0.7412\nValidation Loss: 0.5418, Validation Accuracy: 0.8016\nEpoch 17/20, Training Loss: 0.7054, Training Accuracy: 0.7412\nValidation Loss: 0.5390, Validation Accuracy: 0.8052\nEpoch 18/20, Training Loss: 0.7011, Training Accuracy: 0.7425\nValidation Loss: 0.5534, Validation Accuracy: 0.7974\nEpoch 19/20, Training Loss: 0.7018, Training Accuracy: 0.7415\nValidation Loss: 0.5533, Validation Accuracy: 0.7966\nEpoch 20/20, Training Loss: 0.6936, Training Accuracy: 0.7439\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-08-09 12:27:40,879] Trial 4 finished with value: 0.8052 and parameters: {'learning_rate': 0.006551084078849642, 'batch_size': 64, 'dropout_rate': 0.48073747976393355}. Best is trial 0 with value: 0.888.\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.5627, Validation Accuracy: 0.7944\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test model","metadata":{}},{"cell_type":"code","source":"# Initialize best model\nbest_trial = study.best_trial\nbest_model_weights_path = f'best_model_{best_trial.number}.pth'\nprint(\"Parameters: \", best_trial.params)\nprint(\"Validation Accuracy: \", best_trial.value)\n\nbest_model = Net(dropout_rate=best_trial.params['dropout_rate']).to(device)\nbest_model.load_state_dict(torch.load(best_model_weights_path))\n\n# Evaluate best model on the test set\ntest_loader = DataLoader(test_data, batch_size=best_trial.params['batch_size'], shuffle=False)\ntest_model(best_model, test_loader, nn.CrossEntropyLoss())","metadata":{"execution":{"iopub.status.busy":"2024-08-09T12:57:05.951864Z","iopub.execute_input":"2024-08-09T12:57:05.952498Z","iopub.status.idle":"2024-08-09T12:57:07.998790Z","shell.execute_reply.started":"2024-08-09T12:57:05.952465Z","shell.execute_reply":"2024-08-09T12:57:07.997889Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Parameters:  {'learning_rate': 0.00328964155258187, 'batch_size': 128, 'dropout_rate': 0.1381197686826482}\nValidation Accuracy:  0.888\nTesting Loss: 0.3164, Testing Accuracy: 0.8858\n","output_type":"stream"}]}]}