{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SummerCourse Week2 HW\n## Import library","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-09T08:08:38.357982Z","iopub.execute_input":"2024-08-09T08:08:38.358535Z","iopub.status.idle":"2024-08-09T08:08:44.024052Z","shell.execute_reply.started":"2024-08-09T08:08:38.358504Z","shell.execute_reply":"2024-08-09T08:08:44.022920Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define a custom dataset class","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, csv_file, transform=None):\n        self.data_frame = pd.read_csv(csv_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        image = Image.fromarray(self.data_frame.iloc[idx, 1:].values.reshape(28, 28).astype(np.uint8))\n        label = int(self.data_frame.iloc[idx, 0])\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:08:44.026075Z","iopub.execute_input":"2024-08-09T08:08:44.026797Z","iopub.status.idle":"2024-08-09T08:08:44.035740Z","shell.execute_reply.started":"2024-08-09T08:08:44.026762Z","shell.execute_reply":"2024-08-09T08:08:44.034287Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(degrees=45),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:08:44.036971Z","iopub.execute_input":"2024-08-09T08:08:44.037296Z","iopub.status.idle":"2024-08-09T08:08:44.049073Z","shell.execute_reply.started":"2024-08-09T08:08:44.037266Z","shell.execute_reply":"2024-08-09T08:08:44.048129Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Define dataset and dataloader","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/fashionmnist/fashion-mnist_train.csv'\ntest_path = '/kaggle/input/fashionmnist/fashion-mnist_test.csv'\n\ntrain_data = MyDataset(csv_file=train_path, transform=train_transform)\ntest_data = MyDataset(csv_file=test_path, transform=test_transform)\ntestLen = int(len(test_data) * 0.5)\nvalLen = len(test_data) - testLen\ntest_data, val_data = random_split(test_data, [testLen, valLen])\n\ntrain_loader = DataLoader(train_data, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:08:44.051928Z","iopub.execute_input":"2024-08-09T08:08:44.052798Z","iopub.status.idle":"2024-08-09T08:08:50.793222Z","shell.execute_reply.started":"2024-08-09T08:08:44.052767Z","shell.execute_reply":"2024-08-09T08:08:50.792461Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Define CNN model (initialize model, loss and optimizer)","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n        self.fc2 = nn.Linear(128, 10)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 7 * 7)\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\nmodel = Net().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), weight_decay=0.001, lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:31:47.659556Z","iopub.execute_input":"2024-08-09T08:31:47.659932Z","iopub.status.idle":"2024-08-09T08:31:47.676920Z","shell.execute_reply.started":"2024-08-09T08:31:47.659903Z","shell.execute_reply":"2024-08-09T08:31:47.675936Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"# Training section\ndef train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n    best_accuracy = 0.0\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_train += labels.size(0)\n            correct_train += (predicted == labels).sum().item()\n\n        train_loss = running_loss / len(train_loader.dataset)\n        train_accuracy = correct_train / total_train\n        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n\n        # Evaluate on validation set every epoch\n        model.eval()\n        running_val_loss = 0.0\n        correct_val = 0\n        total_val = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                running_val_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n\n            val_loss = running_val_loss / len(val_loader.dataset)\n            val_accuracy = correct_val / total_val\n\n            if val_accuracy > best_accuracy:\n                # Save model weights\n                torch.save(model.state_dict(), 'best.pth')\n                best_accuracy = val_accuracy\n\n            print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n            \ntrain_model(model, train_loader, val_loader, criterion, optimizer, 20)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:31:51.073102Z","iopub.execute_input":"2024-08-09T08:31:51.073785Z","iopub.status.idle":"2024-08-09T08:44:23.076108Z","shell.execute_reply.started":"2024-08-09T08:31:51.073753Z","shell.execute_reply":"2024-08-09T08:44:23.075179Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/20, Training Loss: 1.0193, Training Accuracy: 0.6232\nValidation Loss: 0.6394, Validation Accuracy: 0.7502\nEpoch 2/20, Training Loss: 0.7509, Training Accuracy: 0.7206\nValidation Loss: 0.5710, Validation Accuracy: 0.7720\nEpoch 3/20, Training Loss: 0.6775, Training Accuracy: 0.7470\nValidation Loss: 0.5397, Validation Accuracy: 0.7952\nEpoch 4/20, Training Loss: 0.6322, Training Accuracy: 0.7672\nValidation Loss: 0.4814, Validation Accuracy: 0.8182\nEpoch 5/20, Training Loss: 0.6012, Training Accuracy: 0.7796\nValidation Loss: 0.4605, Validation Accuracy: 0.8268\nEpoch 6/20, Training Loss: 0.5751, Training Accuracy: 0.7933\nValidation Loss: 0.4355, Validation Accuracy: 0.8376\nEpoch 7/20, Training Loss: 0.5568, Training Accuracy: 0.7987\nValidation Loss: 0.4217, Validation Accuracy: 0.8370\nEpoch 8/20, Training Loss: 0.5364, Training Accuracy: 0.8064\nValidation Loss: 0.4096, Validation Accuracy: 0.8470\nEpoch 9/20, Training Loss: 0.5230, Training Accuracy: 0.8127\nValidation Loss: 0.3992, Validation Accuracy: 0.8484\nEpoch 10/20, Training Loss: 0.5111, Training Accuracy: 0.8151\nValidation Loss: 0.3849, Validation Accuracy: 0.8526\nEpoch 11/20, Training Loss: 0.5025, Training Accuracy: 0.8193\nValidation Loss: 0.3820, Validation Accuracy: 0.8554\nEpoch 12/20, Training Loss: 0.4958, Training Accuracy: 0.8215\nValidation Loss: 0.3910, Validation Accuracy: 0.8550\nEpoch 13/20, Training Loss: 0.4875, Training Accuracy: 0.8259\nValidation Loss: 0.3655, Validation Accuracy: 0.8618\nEpoch 14/20, Training Loss: 0.4801, Training Accuracy: 0.8271\nValidation Loss: 0.3558, Validation Accuracy: 0.8692\nEpoch 15/20, Training Loss: 0.4754, Training Accuracy: 0.8294\nValidation Loss: 0.3480, Validation Accuracy: 0.8722\nEpoch 16/20, Training Loss: 0.4718, Training Accuracy: 0.8310\nValidation Loss: 0.3493, Validation Accuracy: 0.8724\nEpoch 17/20, Training Loss: 0.4662, Training Accuracy: 0.8328\nValidation Loss: 0.3660, Validation Accuracy: 0.8630\nEpoch 18/20, Training Loss: 0.4587, Training Accuracy: 0.8349\nValidation Loss: 0.3486, Validation Accuracy: 0.8738\nEpoch 19/20, Training Loss: 0.4568, Training Accuracy: 0.8357\nValidation Loss: 0.3308, Validation Accuracy: 0.8746\nEpoch 20/20, Training Loss: 0.4530, Training Accuracy: 0.8382\nValidation Loss: 0.3275, Validation Accuracy: 0.8742\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test model","metadata":{}},{"cell_type":"code","source":"# Testing section\ndef test_model(net, testloader):\n    model.eval()\n    running_test_loss = 0.0\n    correct_test = 0\n    total_test = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_test_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n    test_loss = running_test_loss / len(test_loader.dataset)\n    test_accuracy = correct_test / total_test\n\n    print(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')\n\n# Load the best model for testing\nmodel.load_state_dict(torch.load('best.pth'))\ntest_model(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:47:23.048836Z","iopub.execute_input":"2024-08-09T08:47:23.049282Z","iopub.status.idle":"2024-08-09T08:47:25.086295Z","shell.execute_reply.started":"2024-08-09T08:47:23.049250Z","shell.execute_reply":"2024-08-09T08:47:25.085314Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Testing Loss: 0.3118, Testing Accuracy: 0.8918\n","output_type":"stream"}]}]}